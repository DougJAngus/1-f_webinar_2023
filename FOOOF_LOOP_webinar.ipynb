{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Basic functions for running FOOOF across a group of power spectra.\n",
    "#\n",
    "# Created by Douglas Angus, Bond University, 2023.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30f2841",
   "metadata": {
    "cell_depth": 1,
    "lines_to_next_cell": 2,
    "title": "1.1 Loading packages and functions for initial processing"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import fooof\n",
    "from fooof import FOOOFGroup\n",
    "import pandas as pd\n",
    "import os as os\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fooof_loop(subjects, condition, home_dir, file_suffix):\n",
    "    \"\"\"\n",
    "\tLoop through subjects and fit FOOOF model to each subject's power spectrum\n",
    "\t\"\"\"\n",
    "\n",
    "    #Establish dictionary\n",
    "    results = {}\n",
    "    results['ID'] = []\n",
    "    results['exponent'] = []\n",
    "    results['offset'] = []\n",
    "    results['r2'] = []\n",
    "        \n",
    "    for s in range(0, np.size(subjects)):\n",
    "        sub = subjects[s]\n",
    "        \n",
    "        fname = os.path.join(home_dir, (str(sub)+ file_suffix + '.mat'))\n",
    "        dat = spio.loadmat(fname, mdict=None, mat_dtype=True, struct_as_record=False)\n",
    "\n",
    "        ps = dat['SpectraSheetSubject']\n",
    "        ps = 10**(ps/10)\n",
    "                \n",
    "        # first initialize fooof group object\n",
    "        fg = FOOOFGroup(peak_width_limits=[1, 8], min_peak_height=0.1, max_n_peaks=8, aperiodic_mode='fixed')\n",
    "        freq_range = [2, 40]\n",
    "\n",
    "        freqs = np.linspace(1,100, num= np.size(ps,1))\n",
    "\n",
    "        fg.fit(freqs, ps, freq_range) \n",
    "        exps_temp = fg.get_params('aperiodic_params', 'exponent')\n",
    "        offset_temp = fg.get_params('aperiodic_params', 'offset')\n",
    "        r_squ_temp = fg.get_params('r_squared')\n",
    "\n",
    "        # Store results in dictionary\n",
    "        results['ID'].append(sub)\n",
    "        results['exponent'].append(exps_temp[np.newaxis])\n",
    "        results['offset'].append(offset_temp[np.newaxis])\n",
    "        results['r2'].append(r_squ_temp[np.newaxis])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87cf2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_subs = np.array(['sub-010002',\t'sub-010004'])\n",
    "\n",
    "home_dir = os.path.realpath(os.path.join(os.path.abspath(''), '..','EEG_Preprocessed_BIDS_ID','EEG_Preprocessed'))\n",
    "\n",
    "#Run fooof loops over EC and EO data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_suffix = '_EC'\n",
    "EC_results = fooof_loop(good_subs, \"eyes_closed\", home_dir, file_suffix)\n",
    "\n",
    "file_suffix = '_EO'\n",
    "EO_results = fooof_loop(good_subs, \"eyes_open\", home_dir, file_suffix)\n",
    "\n",
    "np.save(os.path.join(home_dir,\"EC_results.npy\"), EC_results)\n",
    "np.save(os.path.join(home_dir,\"EO_results.npy\"), EO_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For getting at each individual measure, its some straight forward wrangling\n",
    "np.array(EC_results['exponent']).squeeze(axis=1) #Replace the varialbe name and key name and you'll get out that data as participants X electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make some more human and machine readable headers\n",
    "chans = (['Fz', 'Cz', 'Afz', 'Pz', 'Oz', 'CPz'])\n",
    "\n",
    "#Make some more human and machine readable headers\n",
    "exponent_header = [s + \"_Exponent\" for s in chans]\n",
    "offset_header = [s + \"_Offset\" for s in chans]\n",
    "fit_header = [s + \"_Fit\" for s in chans]\n",
    "\n",
    "#Combine the headers\n",
    "header_master = flatten([exponent_header,offset_header,fit_header])\n",
    "header_eo = [s + \"_EO\" for s in header_master]\n",
    "header_ec = [s + \"_EC\" for s in header_master]\n",
    "header_eo = np.array(flatten([[\"ID\"],header_eo]))[np.newaxis]\n",
    "header_ec = np.array(flatten([[\"ID\"],header_ec]))[np.newaxis]\n",
    "\n",
    "#Get the data from the EO and EC dicts\n",
    "ec_output = np.squeeze(np.concatenate([np.array(EC_results['exponent']).squeeze(axis=1),np.array(EC_results['offset']).squeeze(axis=1),np.array(EC_results['r2']).squeeze(axis=1)],axis=1))\n",
    "ec_output = np.column_stack((np.array(EC_results['ID']),ec_output))\n",
    "ec_output = np.concatenate((header_ec,ec_output),axis=0)\n",
    "\n",
    "eo_output = np.squeeze(np.concatenate([np.array(EO_results['exponent']).squeeze(axis=1),np.array(EO_results['offset']).squeeze(axis=1),np.array(EO_results['r2']).squeeze(axis=1)],axis=1))\n",
    "eo_output = np.column_stack((np.array(EO_results['ID']),eo_output))\n",
    "eo_output = np.concatenate((header_eo,eo_output),axis=0)\n",
    "\n",
    "#Save the data as a csv and numpy array\n",
    "np.save(os.path.join(home_dir,\"EC_Flat.npy\"), ec_output)\n",
    "np.save(os.path.join(home_dir,\"EO_Flat.npy\"), eo_output)\n",
    "\n",
    "np.savetxt(os.path.join(home_dir,\"EC_Flat.csv\"), ec_output, delimiter=\",\",fmt = '%s')\n",
    "np.savetxt(os.path.join(home_dir,\"EO_Flat.csv\"), eo_output, delimiter=\",\",fmt = '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc968ce-562c-42dc-8d61-3dcd0e8e28c9",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "3 Analysis"
   },
   "outputs": [],
   "source": [
    "# Load the data from the saved .npy files \n",
    "# Pickle must be true. Then use [()] to get at the actual dictionary\n",
    "\n",
    "EC_results = np.load(os.path.join(home_dir,\"EC_results.npy\"),allow_pickle=True).tolist()\n",
    "EO_results = np.load(os.path.join(home_dir,\"EO_results.npy\"),allow_pickle=True).tolist()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "cell_depth,title,-all",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "98d659b6095dbbd11fda86f2236c12ae7352aa7cfc8328087e8b92ec2b08e96e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
